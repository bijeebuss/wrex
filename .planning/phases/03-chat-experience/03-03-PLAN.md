---
phase: 03-chat-experience
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - src/lib/claude/process-manager.ts
  - src/lib/claude/chat-handler.ts
  - src/components/chat/MemoryContext.tsx
  - src/components/chat/ChatMessages.tsx
  - src/hooks/useChat.ts
  - src/routes/_chat.$sessionId.tsx
  - src/routes/_chat.index.tsx
autonomous: false

must_haves:
  truths:
    - "Relevant memory is automatically searched and injected as context for each conversation via --append-system-prompt"
    - "Claude Code has access to MCP memory tools (memory_search, memory_get, memory_write) via --mcp-config on every spawn"
    - "User sees an expandable memory context block at the start of the conversation showing what snippets were loaded"
    - "Tool calls appear as collapsible blocks in the conversation flow with spinner while running and results when done"
    - "Tool blocks are collapsed by default, showing compact header (e.g., 'Searched memory') that expands on click"
    - "The full end-to-end product works: type message -> memory injected -> Claude responds with memory tools available -> response streams with tool blocks visible"
  artifacts:
    - path: "src/lib/claude/process-manager.ts"
      provides: "spawn() accepts appendSystemPrompt and mcpConfigPath options"
    - path: "src/lib/claude/chat-handler.ts"
      provides: "Searches memory before spawning, passes context and MCP config"
    - path: "src/components/chat/MemoryContext.tsx"
      provides: "Expandable block showing injected memory snippets"
  key_links:
    - from: "src/lib/claude/chat-handler.ts"
      to: "src/lib/memory/search.ts"
      via: "hybridSearch called before spawn"
      pattern: "hybridSearch"
    - from: "src/lib/claude/chat-handler.ts"
      to: "src/lib/claude/process-manager.ts"
      via: "spawn with appendSystemPrompt and mcpConfigPath"
      pattern: "appendSystemPrompt.*mcpConfigPath"
    - from: "src/lib/claude/process-manager.ts"
      to: "claude CLI"
      via: "--append-system-prompt and --mcp-config flags"
      pattern: "append-system-prompt.*mcp-config"
---

<objective>
Wire memory injection into the chat pipeline and make tool usage visible in the UI. Claude gets relevant memory context automatically and has access to MCP memory tools. Users see what memory was loaded and what tools Claude uses.

Purpose: This is the core differentiator -- every conversation builds on prior knowledge. Memory injection means Claude has context without the user repeating themselves. Tool visibility means users understand what Claude is doing.

Output: The complete end-to-end product: memory-augmented conversations with visible tool usage. Phase 3 is complete.
</objective>

<execution_context>
@/home/node/.claude/get-shit-done/workflows/execute-plan.md
@/home/node/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-chat-experience/03-RESEARCH.md
@.planning/phases/03-chat-experience/03-01-SUMMARY.md
@.planning/phases/03-chat-experience/03-02-SUMMARY.md

Key existing files to reference:
@src/lib/claude/process-manager.ts (needs --append-system-prompt and --mcp-config flags)
@src/lib/claude/chat-handler.ts (needs hybridSearch before spawn, needs to send memory context as SSE event)
@src/lib/memory/search.ts (hybridSearch function to call)
@src/hooks/useChat.ts (needs to parse memory_context event and track tool calls)
@src/components/chat/ToolBlock.tsx (already created in 03-01, verify it renders correctly)
@src/components/chat/ChatMessages.tsx (needs MemoryContext block at start)
@.mcp.json (MCP config file path for --mcp-config flag)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire memory injection into process manager and chat handler</name>
  <files>
    src/lib/claude/process-manager.ts
    src/lib/claude/chat-handler.ts
  </files>
  <action>
**Update `src/lib/claude/process-manager.ts`:**

Extend the `spawn` method to accept `appendSystemPrompt` and `mcpConfigPath` options:

```typescript
spawn(
  sessionId: string,
  prompt: string,
  opts?: {
    resumeSessionId?: string
    appendSystemPrompt?: string
    mcpConfigPath?: string
  },
): ChildProcess {
  const args = [
    '-p', prompt,
    '--output-format', 'stream-json',
    '--verbose',
    '--include-partial-messages',
    '--dangerously-skip-permissions',
  ]

  if (opts?.resumeSessionId) {
    args.push('--resume', opts.resumeSessionId)
  }

  if (opts?.appendSystemPrompt) {
    args.push('--append-system-prompt', opts.appendSystemPrompt)
  }

  if (opts?.mcpConfigPath) {
    args.push('--mcp-config', opts.mcpConfigPath)
  }

  // ... rest unchanged
}
```

**Update `src/lib/claude/chat-handler.ts`:**

1. Import `hybridSearch` from `@/lib/memory/search`:
   ```typescript
   import { hybridSearch } from '@/lib/memory/search'
   ```
   Import `path` from `node:path` for resolving .mcp.json path.

2. Before spawning the Claude CLI process (after creating the user message), search memory:
   ```typescript
   // Search memory for relevant context
   let memoryContext: { filePath: string; heading: string; content: string; startLine: number; endLine: number }[] = []
   let systemPromptAppend = ''
   try {
     const results = await hybridSearch(prompt, 3)
     if (results.length > 0) {
       memoryContext = results.map(r => ({
         filePath: r.filePath,
         heading: r.heading,
         content: r.content,
         startLine: r.startLine,
         endLine: r.endLine,
       }))
       const contextSnippets = results.map(r =>
         `[${r.filePath}:${r.startLine}-${r.endLine}] ${r.heading}\n${r.content}`
       ).join('\n\n---\n\n')
       systemPromptAppend = `\n\nRelevant memory context from prior sessions:\n${contextSnippets}`
     }
   } catch (err) {
     console.error('[chat] Memory search failed (non-fatal):', err)
     // Continue without memory context -- non-fatal
   }
   ```

3. Resolve the MCP config path:
   ```typescript
   const mcpConfigPath = path.resolve('.mcp.json')
   ```

4. Pass both to process manager spawn:
   ```typescript
   child = processManager.spawn(sessionId, prompt, {
     resumeSessionId: claudeResumeSessionId,
     appendSystemPrompt: systemPromptAppend || undefined,
     mcpConfigPath,
   })
   ```

5. Send memory context as the second SSE event (after the session event, before Claude starts streaming):
   ```typescript
   if (memoryContext.length > 0) {
     controller.enqueue(
       encoder.encode(`data: ${JSON.stringify({
         type: 'memory_context',
         snippets: memoryContext,
       })}\n\n`)
     )
   }
   ```

**Important notes:**
- hybridSearch is async (it embeds the query), so the handleChatRequest function already returns a Promise -- no change needed there
- Memory search is non-fatal: if it fails (e.g., no indexed memory, embedder not loaded), continue without context
- Always pass --mcp-config on every spawn (even when resuming) per research recommendation
- The --append-system-prompt value should be a string, not a file path
  </action>
  <verify>
  1. Send a chat message and check server logs for "[chat] Memory search" output
  2. Verify that the SSE stream includes a `memory_context` event with snippets (if memory is indexed)
  3. Check Claude CLI spawned with `--append-system-prompt` and `--mcp-config` flags by adding a temporary console.log of the args array
  </verify>
  <done>
  Process manager accepts and passes --append-system-prompt and --mcp-config flags. Chat handler searches memory before spawning Claude, injects relevant context, sends memory_context SSE event to client, and always passes MCP config for tool access.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add memory context display and enhance tool block visibility in UI</name>
  <files>
    src/components/chat/MemoryContext.tsx
    src/components/chat/ChatMessages.tsx
    src/hooks/useChat.ts
    src/routes/_chat.$sessionId.tsx
    src/routes/_chat.index.tsx
  </files>
  <action>
**Create `src/components/chat/MemoryContext.tsx`:**
An expandable block at the start of the conversation showing injected memory snippets:
- Uses `<details>` + `<summary>` for native expand/collapse
- Collapsed by default
- Summary shows: icon + "Memory context loaded" + snippet count (e.g., "3 snippets")
- Expanded view shows each snippet with:
  - File path and line range in muted text
  - Heading in semibold
  - Content preview (first 200 chars, with "..." if truncated)
- Styling: subtle system-message appearance, not a chat bubble. Use a light border, slightly different background (e.g., bg-gray-50 dark:bg-gray-900/50), rounded-lg, mx-auto max-w-2xl
- Import MemorySnippet type from `@/types/chat`

```tsx
interface MemoryContextProps {
  snippets: MemorySnippet[]
}

function MemoryContext({ snippets }: MemoryContextProps) {
  return (
    <div className="mx-auto max-w-2xl mb-4">
      <details className="rounded-lg border border-gray-200 dark:border-gray-700 bg-gray-50 dark:bg-gray-900/50 overflow-hidden">
        <summary className="px-4 py-2.5 cursor-pointer flex items-center gap-2 text-sm text-gray-500 dark:text-gray-400 hover:bg-gray-100 dark:hover:bg-gray-800/50">
          <svg className="w-4 h-4" ...> {/* brain/memory icon */} </svg>
          Memory context loaded
          <span className="ml-auto text-xs text-gray-400">{snippets.length} snippet{snippets.length !== 1 ? 's' : ''}</span>
        </summary>
        <div className="px-4 py-3 border-t border-gray-200 dark:border-gray-700 space-y-3">
          {snippets.map((s, i) => (
            <div key={i} className="text-sm">
              <div className="text-xs text-gray-400 font-mono">{s.filePath}:{s.startLine}-{s.endLine}</div>
              {s.heading && <div className="font-medium text-gray-600 dark:text-gray-300">{s.heading}</div>}
              <p className="text-gray-500 dark:text-gray-400 mt-0.5">
                {s.content.length > 200 ? s.content.slice(0, 200) + '...' : s.content}
              </p>
            </div>
          ))}
        </div>
      </details>
    </div>
  )
}
```

**Update `src/hooks/useChat.ts`:**
1. Add `memoryContext: MemorySnippet[] | null` to hook state (initialized to null)
2. In SSE event parsing, handle the `memory_context` event type:
   ```typescript
   if (event.type === 'memory_context' && event.snippets) {
     setMemoryContext(event.snippets)
   }
   ```
3. Add `memoryContext` to the return value

**Update `src/components/chat/ChatMessages.tsx`:**
1. Accept `memoryContext: MemorySnippet[] | null` prop
2. Render `<MemoryContext snippets={memoryContext} />` at the top of the message list (before any messages) when memoryContext is not null and has items
3. Verify that ToolBlock components render correctly within assistant messages:
   - When a message has `toolCalls`, render a ToolBlock for each between/after the text content
   - ToolBlock should already exist from 03-01 -- verify it integrates properly

**Update route components:**
In both `_chat.index.tsx` and `_chat.$sessionId.tsx`:
- Pass `memoryContext` from useChat to ChatMessages component
- Ensure the useChat hook return includes memoryContext

**Verify tool block integration end-to-end:**
- When Claude uses a tool during streaming, the useChat hook should track it via content_block_start/stop events
- The current assistant message should have toolCalls populated
- ChatMessage component should render ToolBlock for each tool call
- ToolBlock shows spinner while running, checkmark when complete
- Collapsed by default with human-readable name
- Test this by checking that when Claude calls memory_search, a "Searched memory" block appears in the chat
  </action>
  <verify>
  1. Start a new chat and send a message -- verify memory context block appears at top (if memory is indexed)
  2. Memory context block is collapsed by default, expandable to see snippets
  3. If Claude uses MCP tools during response, tool blocks appear in the chat flow
  4. Tool blocks show spinner while executing, then results when done
  5. Tool blocks are collapsed by default with human-readable names
  6. `npx tsc --noEmit` passes
  </verify>
  <done>
  Memory context block displays at the start of conversations showing loaded snippets. Tool calls appear as collapsible blocks in the chat flow with spinners and results. The full pipeline works: message sent -> memory searched -> context injected -> Claude responds with tool access -> tool usage visible in UI.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: End-to-end verification of the complete product</name>
  <what-built>
  The complete Wrex chat application:
  - Streaming chat with bubble-style messages, markdown rendering, syntax-highlighted code blocks
  - Session management with sidebar, new chat, resume, delete
  - Memory injection and MCP tool access
  - Tool usage visibility with collapsible blocks
  - Auto-scroll, loading indicators, error handling, message queuing
  - Dark mode based on system preference
  </what-built>
  <how-to-verify>
  1. Start dev server: `npx vite dev`
  2. Open in browser -- verify dark mode matches system preference
  3. Sidebar should be visible on the left with "New chat" button
  4. Type a message in the input area -- verify auto-expanding textarea
  5. Press Enter to send -- verify:
     a. User message appears in a right-aligned colored bubble
     b. Loading dots appear while waiting for first token
     c. Claude's response streams token-by-token in a left-aligned bubble
     d. Markdown renders properly (try asking Claude to write code)
     e. Code blocks have syntax highlighting and a copy button
  6. If memory was indexed (run `npm run memory:index` first), verify:
     a. Memory context block appears at top of conversation
     b. Expandable to see loaded snippets
  7. If Claude uses MCP tools, verify collapsible tool blocks appear
  8. Test session management:
     a. Session appears in sidebar with auto-generated title
     b. Click "New chat" -- sidebar shows previous session
     c. Click previous session -- full message history loads
     d. Send another message in the resumed session
     e. Delete a session from the sidebar
  9. Test auto-scroll: send a message that produces a long response, try scrolling up during streaming
  10. Test error handling: stop Claude mid-stream with the Stop button
  11. On narrow viewport (< 768px): sidebar collapses to hamburger
  </how-to-verify>
  <resume-signal>Type "approved" to complete Phase 3, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` -- TypeScript compiles without errors
2. Full end-to-end: send message -> memory injected -> Claude responds -> stream renders -> session saved
3. Memory context block visible and expandable
4. Tool call blocks visible, collapsed by default, spinner while running
5. All session management features work (new, browse, resume, delete)
6. Dark mode without flash
7. Auto-scroll behavior correct
8. Error handling with retry
</verification>

<success_criteria>
- Memory is searched and injected as context on every message via --append-system-prompt
- MCP config always passed via --mcp-config for memory tool access
- Memory context block appears at conversation start, expandable
- Tool calls visible as collapsible blocks in conversation flow
- Complete end-to-end product works: chat + sessions + memory + tools
- Human verification passes
</success_criteria>

<output>
After completion, create `.planning/phases/03-chat-experience/03-03-SUMMARY.md`
</output>
